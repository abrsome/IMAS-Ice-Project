{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01eab298",
   "metadata": {},
   "source": [
    "# RF SIE 1903 Prediction\n",
    "\n",
    "This script was used for generating the SIE regression found in the _1903Prediction.nc_ file.\n",
    "\n",
    "This regression was saved as an output as we decided that for now (31/08/2022) it would be useful to just have a base product of the current best prediction for all sea ice going back to the start of the 20th century.\n",
    "\n",
    "\n",
    "##### From some prior investigation:\n",
    "Using a monthly mode of prediction seems to work best in most models, so the most important thing was picking which years to use in the training period, as picking a longer period means more training data but fewer available proxies, e.g. Law Dome MSA available up until 1995, AP_stacked_MSA to 2002, WHG_dex to 2006... Training always starts in 1979 as those are the first satellite records.\n",
    "\n",
    "2006 as the end year of the training period is the sweet spot for the current version of the model: Loss of Law Dome and AP  MSA proxies appears to be offset by the gains provided by having a longer training period. Progressing past 2006 we see error in the model increase again as further loss of proxies is not outweighed by gain of additional training data.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae957e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from calendar import month_abbr "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726ca675",
   "metadata": {},
   "source": [
    "Grab in the list of month contractions and pop the empty string so it can be used in the graphs for axis tick labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1a59de",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = list(month_abbr)\n",
    "months.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5f35eb",
   "metadata": {},
   "source": [
    "Set the number of estimators (= trees in each forest), as well as seeding a random state for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10be9c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = 200 #number of estimators\n",
    "rs = 0 #random state\n",
    "np.random.seed(rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d4124e",
   "metadata": {},
   "source": [
    "Next we specify the years which will be used for:\n",
    "- the start of the prediction period (predstartyear)\n",
    "- the start of the training/testing data (startyear)\n",
    "- the end of the training/testing data (endyear)\n",
    "- the number of years we are predicting for (predyears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5a2f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "predstartyear = 1903 #start of predicted period\n",
    "startyear = 1979 #start of training\n",
    "endyear = 2006 #end of training\n",
    "predyears = startyear-predstartyear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384ebcf1",
   "metadata": {},
   "source": [
    "Then we specify filepaths and open the data for our prediction and training sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75d8593",
   "metadata": {},
   "outputs": [],
   "source": [
    "yvar = 'SIE'\n",
    "folder = '~/Desktop/IMAS/ncfiles/'  #filepath\n",
    "pfile = 'Proxy_combined_data_v4.nc'  #proxy filename\n",
    "xfile = 'CombinedProxies.nc'  #proxy filename\n",
    "df = xr.open_dataset(folder+pfile).sel(year= slice(startyear, endyear))\n",
    "X = xr.open_dataset(folder+xfile).sel(year= slice(predstartyear, endyear))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba98763c",
   "metadata": {},
   "source": [
    "Then we drop predictors containing NaN values in this range.\n",
    "\n",
    "__Note:__ We must do this as RFs cannot handle NaN values, there are many alternative options here such as:\n",
    "- using the mean to impute values\n",
    "- using a RF based on other proxies in that year (or only complete years) to impute\n",
    "- using a known distribution to impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1618361e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_dataframe().dropna(axis=1).to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652e3775",
   "metadata": {},
   "source": [
    "This script is adapted from one with many modes of prediction, so get the output mode names in an array and set the mode to 1 as we are using _Monthly_ predictions for higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5629509",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputname = ['Individual','Month','Longitudinal','Year']\n",
    "mode = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dbd520",
   "metadata": {},
   "source": [
    "Then log the mean SIE for use in calculating error%.\n",
    "\n",
    "__Note:__ you could also calculate the mean SIE in each month, or at each longitude, for different ways of considering the error. I have used this as it was the simplest to implement in a short amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe7216d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sie = df[yvar].mean('month').mean('lon').mean('year')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26f9fe2",
   "metadata": {},
   "source": [
    "Next generate a train test split.\n",
    "\n",
    "I am doing this here by randomly selecting arrays of years instead of using sklearn traintest split as not all the splits are done simultaneously and therefore can't all be done in one call of the function to maintain the same splits. So, I need to generate year lists here to ensure the years in train/test data are consistent  across X and y's. Note that the split is seeded by the numpy random seed above to be reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce1515",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(startyear, endyear+1)\n",
    "testyears = np.sort(np.random.choice(years, size = int(len(years)*0.33), replace = False))\n",
    "trainyears = [x for x in years if x not in testyears]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7ecab",
   "metadata": {},
   "source": [
    "Select the correct section of predictor data for train/test/regression and then standard scale them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e893fa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.sel(year = trainyears).to_dataframe().values\n",
    "X_test = X.sel(year = testyears).to_dataframe().values\n",
    "\n",
    "#X_reg is the predictors in the regression time period\n",
    "X_reg = X.sel(year = slice(predstartyear,startyear-1)).to_dataframe().values\n",
    "\n",
    "#Standardise values of proxies\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_reg = sc.transform(X_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a2ea20",
   "metadata": {},
   "source": [
    "Group the SIE into bins of 10 degree longitude sections for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f49ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[yvar].groupby_bins('lon', np.arange(0,361,10)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c386a0",
   "metadata": {},
   "source": [
    "Initialise an array to store the Root Mean Squared Error as Percentage of Mean (rmsepom) for the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87237910",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsepom = np.zeros([12,36])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9698f0f1",
   "metadata": {},
   "source": [
    "Initialise an array to store the results of the regression for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression = np.zeros([predyears,12,36])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a383f9f",
   "metadata": {},
   "source": [
    "Loop through the months, building each a model to predicit for all longitudes in that month. Log the model's error as well as the prediction for the predyears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df1b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(12): #loop over the months\n",
    "    m += 1 #month index in xarray starts at 1\n",
    "    monthdata = y.sel(month=m)\n",
    "    y_train = monthdata.sel(year = trainyears).to_numpy()\n",
    "    y_test = monthdata.sel(year = testyears).to_numpy()\n",
    "    \n",
    "    #Training model\n",
    "    regressor = RandomForestRegressor(n_estimators = n_est, random_state = rs)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    \n",
    "    y_reg = regressor.predict(X_reg) #yr=0 for 1903\n",
    "    \n",
    "    #Convert nested arrays from longitudes to year time series\n",
    "    y_test = y_test.transpose()\n",
    "    y_pred = y_pred.transpose() \n",
    "    \n",
    "    for long in range(36):\n",
    "        rmse = np.sqrt(metrics.mean_squared_error(y_test[long], y_pred[long]))\n",
    "        rmsepom[m-1,long] = 100*rmse/mean_sie\n",
    "    \n",
    "    for yr in range(predyears):\n",
    "        regression[yr,m-1] = y_reg[yr]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f893e523",
   "metadata": {},
   "source": [
    "---\n",
    "### Analysing the model\n",
    "\n",
    "First, define a function to plot a heatmap of the error from the model stored in rmsepom. This shows the RMSEPOM at each month/longitude section for the model with a colour scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50521a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(rmsepom):\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    rmsepomxr = xr.DataArray(rmsepom)\n",
    "    rmsepomxr.plot.pcolormesh(levels = clev)\n",
    "    \n",
    "    ax.set_title('Error in '+yvar+' predictions using RFs')\n",
    "    ax.set_ylabel('Month')\n",
    "    #plt.yticks(ticks=np.arange(12))\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_xticks(ticks=np.arange(3,36,3), labels=['','60E','','120E','','180','','120W','','60W',''])\n",
    "    ax.set_yticks(ticks=np.arange(12), labels=months, rotation=0)\n",
    "    ax.annotate(\"Mode = {}\".format(outputname[mode]), xy = (0,0), xytext = (-6,-2.1))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caac446",
   "metadata": {},
   "source": [
    "Next, define a function to plot the error distribution. This produces a histogram of the error values into 2% bins. It is also annotated with green, orange, and red lines to show where the 50th, 75th, and 95th percentiles of error respecitvely fall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97cf8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawerror(rmsepom):\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    ordered = rmsepom.copy()\n",
    "    ordered.ravel().sort()\n",
    "    \n",
    "    x1 = np.percentile(ordered.ravel(), 50)\n",
    "    plt.plot([x1, x1], [0, 100], color='g', linestyle='dashed', linewidth=2)\n",
    "    ax.annotate(\"50%: {}\".format(round(x1,1)), xy = (35,100), color = 'g')\n",
    "    \n",
    "    x1 = np.percentile(ordered.ravel(), 75)\n",
    "    ax.annotate(\"75%: {}\".format(round(x1,1)), xy = (35,92.5), color = 'tab:orange')\n",
    "    plt.plot([x1, x1], [0, 100], color='tab:orange', linestyle='dashed', linewidth=2)\n",
    "    \n",
    "    x1 = np.percentile(ordered.ravel(), 95)\n",
    "    plt.plot([x1, x1], [0, 100], color='r', linestyle='dashed', linewidth=2)\n",
    "    ax.annotate(\"95%: {}\".format(round(x1,1)), xy = (35,85), color='r')\n",
    "    \n",
    "    plt.hist(ordered.ravel(), bins = np.arange(0,41,2))\n",
    "    \n",
    "    ax.set_title('Error distribution for mode: {}'.format(outputname[mode]))\n",
    "    ax.set_ylabel('Number of Values')\n",
    "    ax.set_xlabel('Error%')\n",
    "    ax.set_yticks(ticks=np.arange(0,120,10))\n",
    "    ax.set_xticks(ticks=np.arange(0,41,2))\n",
    "    ax.annotate(\"Estimators = {}\".format(n_est), xy = (0,0), xytext = (-6,-20))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50f37c6",
   "metadata": {},
   "source": [
    "Generate some generic metrics of the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a68c8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=========================================================\")\n",
    "print('Error in '+yvar+' predictions using RFs with Output Mode = {}'.format(outputname[mode]))\n",
    "print('RMSE % minimum: ', rmsepom.min())\n",
    "print('RMSE % maximum: ', rmsepom.max())\n",
    "print('RMSE % mean: ', rmsepom.mean())\n",
    "print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0323b5b8",
   "metadata": {},
   "source": [
    "Draw the heatmaps by setting up contour levels and calling the draw and drawerror functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55743069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contour levels for 'zoomed out'\n",
    "clev = np.arange(0,30,2)  #contour levels\n",
    "draw(rmsepom)\n",
    "\n",
    "#Contour levels for 5%\n",
    "clev = np.arange(0,5,.25)  #contour levels\n",
    "draw(rmsepom)\n",
    "\n",
    "drawerror(rmsepom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7985a2",
   "metadata": {},
   "source": [
    "Next, load the data into a _prediction_ variable as an xarray DataArray and format it to have the correct coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d9a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = xr.DataArray(regression,attrs=dict(description=(\"Prediction of SIE 1903 to 1978\")))\n",
    "prediction = prediction.rename({'dim_0': 'year', 'dim_1':'month','dim_2':'lon'})\n",
    "prediction = prediction.assign_coords(year = np.arange(1903,1979))\n",
    "prediction = prediction.assign_coords(month = np.arange(1,13))\n",
    "prediction = prediction.assign_coords(lon = np.arange(0,360,10))\n",
    "prediction = prediction.to_dataset(name = 'SIE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49169d88",
   "metadata": {},
   "source": [
    "Print out the list of proxies used by this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df04581",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Proxies used are:')\n",
    "print(list(X.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc99e91",
   "metadata": {},
   "source": [
    "Finally, export the data to a netCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef50dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filedirectory = r\"C:\\Users\\Alfie\\Desktop\\IMAS\\ncfiles\\1903Prediction.nc\"\n",
    "prediction.to_netcdf(filedirectory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
