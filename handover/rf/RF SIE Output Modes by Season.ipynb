{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36ab89c7",
   "metadata": {},
   "source": [
    "# RF SIE Output Modes by Season\n",
    "\n",
    "This script is a different version of [the 'by Month' random forest model found here](./RF%20SIE%20Output%20Modes%20by%20Month.ipynb). This script looks at building and evaluating models for SIE regression by __Season__ with different modes of prediction, it does not actually compute a 20th century regression (for that, look at _RF SIE 1903 Prediction_).\n",
    "\n",
    "Please read preamble to link [this notebook on the 'by Month' version](./RF%20SIE%20Output%20Modes%20by%20Month.ipynb) before reading this notebook. Most of the code is the same.\n",
    "\n",
    "<hr style=\"height:1px;border-width:0;color:black;background-color:black\">\n",
    "\n",
    "##### A note on the seasonal dataset:\n",
    "In this version, we convert the monthly dataset into one which is made up of overlapping 3-month seasons instead of using 12 individual months. __NOTE: This version currently only uses the 10 3-month seasons which do not 'wrap around' the end of a calendar year (DFJ, NDJ). It was easier and quicker to work with these 10 seasons for proof of concept rather than writing more complex code to deal with calculating the 'wrap around' seasons given the little time available.__\n",
    "\n",
    "(This note is also found at the relevant code below.)\n",
    "\n",
    "---\n",
    "## Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b241f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from calendar import month_abbr "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d11f125",
   "metadata": {},
   "source": [
    "Grab in the list of month contractions and pop the empty string so it can be used in the graphs for axis tick labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085ef362",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = list(month_abbr)\n",
    "months.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d02aa5a",
   "metadata": {},
   "source": [
    "Set the number of estimators (= trees in each forest), as well as seeding a random state for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ae946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = 200 #number of estimators\n",
    "md = None #max depth\n",
    "rs = 0 #random state\n",
    "np.random.seed(rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d933ed1",
   "metadata": {},
   "source": [
    "Next we specify the years which will be used for:\n",
    "- the start of the prediction period (predstartyear)\n",
    "- the start of the training/testing data (startyear)\n",
    "- the end of the training/testing data (endyear)\n",
    "- the number of years we are predicting for (predyears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f82d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "predstartyear = 1979 #start of predicted period\n",
    "startyear = 1979\n",
    "endyear = 1995"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d40ced",
   "metadata": {},
   "source": [
    "Then we specify filepaths and open the data for our prediction and training sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83025d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "yvar = 'SIE'\n",
    "folder = '~/Desktop/IMAS/ncfiles/'  #filepath\n",
    "pfile = 'Proxy_combined_data_v4.nc'  #proxy filename\n",
    "xfile = 'CombinedProxies.nc'  #proxy filename\n",
    "df = xr.open_dataset(folder+pfile).sel(year= slice(startyear, endyear))\n",
    "X = xr.open_dataset(folder+xfile).sel(year= slice(predstartyear, endyear))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c046446e",
   "metadata": {},
   "source": [
    "Then we drop predictors containing NaN values in this range.\n",
    "\n",
    "__Note:__ We must do this as RFs cannot handle NaN values, there are many alternative options here such as:\n",
    "- using the mean to impute values\n",
    "- using a RF based on other proxies in that year (or only complete years) to impute\n",
    "- using a known distribution to impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088ec3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_dataframe().dropna(axis=1).to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ee2005",
   "metadata": {},
   "source": [
    "As mentioned in [the preamble to this notebook on the 'by Month' version](./RF%20SIE%20Output%20Modes%20by%20Month.ipynb), there are four modes of prediction, so we set that number here and construct an array with their names in the fixed order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc803c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputmodes = 4 #number of output modes\n",
    "outputname = ['Individual','Month','Longitudinal','Year']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ae75a3",
   "metadata": {},
   "source": [
    "Then log the mean SIE for use in calculating error%.\n",
    "\n",
    "__Note:__ you could also calculate the mean SIE in each month, or at each longitude, for different ways of considering the error. I have used this as it was the simplest to implement in a short amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757a4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sie = df['SIE'].mean('month').mean('lon').mean('year')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe60ae0",
   "metadata": {},
   "source": [
    "Next generate a train test split.\n",
    "\n",
    "I am doing this here by randomly selecting arrays of years instead of using sklearn traintest split as not all the splits are done simultaneously and therefore can't all be done in one call of the function to maintain the same splits. So, I need to generate year lists here to ensure the years in train/test data are consistent  across X and y's. Note that the split is seeded by the numpy random seed above to be reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a476c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(startyear, endyear+1)\n",
    "testyears = np.sort(np.random.choice(years, size = int(len(years)*0.33), replace = False))\n",
    "trainyears = [x for x in years if x not in testyears]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa080bcf",
   "metadata": {},
   "source": [
    "Select the correct section of predictor data for train/test and then standard scale them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838253f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.sel(year = trainyears).to_dataframe().values\n",
    "X_test = X.sel(year = testyears).to_dataframe().values\n",
    "\n",
    "#Standardise values of proxies\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdae8385",
   "metadata": {},
   "source": [
    "Group the SIE into bins of 10 degree longitude sections for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f2c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[yvar].groupby_bins('lon', np.arange(0,361,10)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beed04f2",
   "metadata": {},
   "source": [
    "##### This is the difference to the 'by Month' version of the model:\n",
    "\n",
    "Here, we convert the monthly dataset into one which is made up of overlapping 3-month seasons instead of using 12 individual months. __NOTE: This version currently only uses the 10 3-month seasons which do not 'wrap around' the end of a calendar year (DFJ, NDJ). It was easier and quicker to work with these 10 seasons for proof of concept rather than writing more complex code to deal with calculating the 'wrap around' seasons given the little time available.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4326192",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indexing works as follows: 0=JFM, 1= FMA, ..., 9=OND\n",
    "seasonal = np.empty([10, y.shape[0],36])\n",
    "for m in range(10):\n",
    "    m+=1\n",
    "    months = [m, m+1, m+2]\n",
    "    seasonal[m-1] = y.sel(month = months).mean('month')\n",
    "\n",
    "#Change indexing of seasonal to be [year, season, longitude]\n",
    "seasonal = seasonal.transpose([1,0,2])\n",
    "#Form xarray version\n",
    "sxr = xr.DataArray(seasonal)\n",
    "dicti = {'dim_0': 'year', 'dim_1': 'season', 'dim_2': 'lon'}\n",
    "sxr = sxr.rename(dicti)\n",
    "sxr = sxr.assign_coords(year=(np.arange(startyear,endyear+1)),\n",
    "                        lon=(np.arange(10,361,10)),\n",
    "                        season=(np.arange(1,11)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12280401",
   "metadata": {},
   "source": [
    "Initialise an empty array to store each array of the Root Mean Squared Error as Percentage of Mean (rmsepom) for the each model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44eb0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "errorarrays = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d463885",
   "metadata": {},
   "source": [
    "Loop through each of the modes, producing the models for each section and logging their error in rmsepom before appending rmsepom to errorarrays to save it.\n",
    "\n",
    "For the multioutput modes (not Individual) the test prediction is generated as an array of values, so we need to iterate through the array produced by the model to deconstruct it into the results for each time/longitude intersection.\n",
    "\n",
    "Note that the xarray dimension for month starts at 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745d166",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in range(outputmodes):\n",
    "    #Array to store root mean square error as percentage of mean\n",
    "    #RMSEPOM = Root Mean Squared Error as Percentage Of Mean\n",
    "    rmsepom = np.zeros([10,36]) #Initialise an array of correlations\n",
    "    \n",
    "    if(mode == 0): #Individual = consider each month/lon pair separately\n",
    "        for s in range(10): #loop over the months\n",
    "            s += 1 #month index in xarray starts at 1\n",
    "            monthdata = sxr.sel(season=s)\n",
    "            for long in range(36): \n",
    "                longend = (long+1)*10 #end of range of longitude section\n",
    "                monthlondata = monthdata.sel(lon=longend)\n",
    "                y_train = monthlondata.sel(year = trainyears).to_numpy()\n",
    "                y_test = monthlondata.sel(year = testyears).to_numpy()\n",
    "                \n",
    "                #Training model\n",
    "                regressor = RandomForestRegressor(n_estimators = n_est,\n",
    "                                                  random_state = rs, max_depth = md)\n",
    "                regressor.fit(X_train, y_train)\n",
    "                y_pred = regressor.predict(X_test)\n",
    "                rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "                \n",
    "                #Put error into heatmap\n",
    "                rmsepom[s-1,int((longend-10)/10)] = 100*rmse/mean_sie\n",
    "        errorarrays.append(rmsepom) #Add in error array for this mode\n",
    "        \n",
    "    elif(mode == 1): #Month = consider data from all longitudes in a month as one target\n",
    "        for s in range(10): #loop over the months\n",
    "            s += 1 #month index in xarray starts at 1\n",
    "            monthdata = sxr.sel(season=s)\n",
    "            y_train = monthdata.sel(year = trainyears).to_numpy()\n",
    "            y_test = monthdata.sel(year = testyears).to_numpy()\n",
    "            \n",
    "            #Training model\n",
    "            regressor = RandomForestRegressor(n_estimators = n_est, \n",
    "                                                  random_state = rs, max_depth = md)\n",
    "            regressor.fit(X_train, y_train)\n",
    "            y_pred = regressor.predict(X_test)\n",
    "            \n",
    "            #Convert nested arrays from longitudes to year time series\n",
    "            y_test = y_test.transpose()\n",
    "            y_pred = y_pred.transpose() \n",
    "            \n",
    "            for long in range(36):\n",
    "                rmse = np.sqrt(metrics.mean_squared_error(y_test[long], y_pred[long]))\n",
    "                rmsepom[s-1,long] = 100*rmse/mean_sie\n",
    "                \n",
    "        errorarrays.append(rmsepom) #Add in error array for this mode\n",
    "        \n",
    "    elif(mode == 2): #Longitudinal = consider data from all months in that longitude as one target\n",
    "        for long in range(36):\n",
    "            longend = (long+1)*10\n",
    "            longdata = sxr.sel(lon = longend)\n",
    "            y_train = longdata.sel(year = trainyears).to_numpy()\n",
    "            y_test = longdata.sel(year = testyears).to_numpy()\n",
    "            \n",
    "            #Training model\n",
    "            regressor = RandomForestRegressor(n_estimators = n_est, \n",
    "                                                  random_state = rs, max_depth = md)\n",
    "            regressor.fit(X_train, y_train)\n",
    "            y_pred = regressor.predict(X_test)\n",
    "            \n",
    "            #Convert nested arrays from months to year time series\n",
    "            y_test = y_test.transpose()\n",
    "            y_pred = y_pred.transpose() \n",
    "            \n",
    "            for s in range(10):\n",
    "                rmse = np.sqrt(metrics.mean_squared_error(y_test[s], y_pred[s]))\n",
    "                rmsepom[s, long] = 100*rmse/mean_sie\n",
    "        \n",
    "        errorarrays.append(rmsepom) #Add in error array for this mode\n",
    "    \n",
    "    elif(mode == 3): #Year = consider the entire year's data as a target variable\n",
    "        y_train = sxr.sel(year = trainyears).to_numpy()\n",
    "        y_train = y_train.reshape(y_train.shape[0], y_train.shape[1] * y_train.shape[2]) # 360 entries per year\n",
    "        y_test = y.sel(year = testyears).to_numpy()\n",
    "        \n",
    "        #Training model\n",
    "        regressor = RandomForestRegressor(n_estimators = n_est, \n",
    "                                                  random_state = rs, max_depth = md)\n",
    "        regressor.fit(X_train, y_train)\n",
    "        y_pred = regressor.predict(X_test)\n",
    "        \n",
    "        #Transform pred and test into standard format to get time series\n",
    "        y_pred = y_pred.reshape(y_pred.shape[0],10,36).transpose()\n",
    "        y_test = y_test.transpose()\n",
    "        \n",
    "        \n",
    "        for l in range(36):\n",
    "            for s in range(10):\n",
    "                rmse = np.sqrt(metrics.mean_squared_error(y_test[l,s], y_pred[l,s]))\n",
    "                rmsepom[s,l] = 100*rmse/mean_sie   \n",
    "                \n",
    "        errorarrays.append(rmsepom) #Add in error array for this mode                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708d8afa",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-width:0;color:black;background-color:black\">\n",
    "\n",
    "### Analysing the model\n",
    "\n",
    "First, define a function to plot a heatmap of the error from the model stored in rmsepom. This shows the RMSEPOM at each month/longitude section for the model with a colour scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41f1451",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(rmsepom):\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    rmsepomxr = xr.DataArray(rmsepom)\n",
    "    rmsepomxr.plot.pcolormesh(levels = clev)\n",
    "    \n",
    "    ax.set_title('Error in '+yvar+' predictions using RFs')\n",
    "    ax.set_ylabel('Month')\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_xticks(ticks=np.arange(3,36,3), labels=['','60E','','120E','','180','','120W','','60W',''])\n",
    "    ax.set_yticks(ticks=np.arange(0,10,1), labels=['JFM','FMA','MAM','AMJ','MJJ','JJA','JAS','ASO','SON','OND'], rotation=0)\n",
    "    ax.annotate(\"Mode = {}\".format(outputname[mode]), xy = (0,0), xytext = (-6,-2.1))\n",
    "    \n",
    "    #Seasonal axis read downwards\n",
    "    #Annotate how to read seasonal axis\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b73ef",
   "metadata": {},
   "source": [
    "Next, define a function to plot the error distribution. This produces a histogram of the error values into 2% bins. It is also annotated with green, orange, and red lines to show where the 50th, 75th, and 95th percentiles of error respecitvely fall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c65d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawerror(rmsepom):\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    ordered = rmsepom.copy()\n",
    "    ordered.ravel().sort()\n",
    "    \n",
    "    x1 = np.percentile(ordered.ravel(), 50)\n",
    "    plt.plot([x1, x1], [0, 100], color='g', linestyle='dashed', linewidth=2)\n",
    "    ax.annotate(\"50%: {}\".format(round(x1,1)), xy = (35,100), color = 'g')\n",
    "    \n",
    "    x1 = np.percentile(ordered.ravel(), 75)\n",
    "    ax.annotate(\"75%: {}\".format(round(x1,1)), xy = (35,92.5), color = 'tab:orange')\n",
    "    plt.plot([x1, x1], [0, 100], color='tab:orange', linestyle='dashed', linewidth=2)\n",
    "    \n",
    "    x1 = np.percentile(ordered.ravel(), 95)\n",
    "    plt.plot([x1, x1], [0, 100], color='r', linestyle='dashed', linewidth=2)\n",
    "    ax.annotate(\"95%: {}\".format(round(x1,1)), xy = (35,85), color='r')\n",
    "    \n",
    "    plt.hist(ordered.ravel(), bins = np.arange(0,41,2))\n",
    "    \n",
    "    ax.set_title('Error distribution for mode: {}'.format(outputname[mode]))\n",
    "    ax.set_ylabel('Number of Values')\n",
    "    ax.set_xlabel('Error%')\n",
    "    ax.set_yticks(ticks=np.arange(0,120,10))\n",
    "    ax.set_xticks(ticks=np.arange(0,41,2))\n",
    "    ax.annotate(\"Estimators = {}\".format(n_est), xy = (0,0), xytext = (-6,-20))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b25782",
   "metadata": {},
   "source": [
    "Finally, loop through each of the modes, putting the RMSEPOM array for that mode into the rmsepom variable. Then, produce some generic metrics and draw the 3 error charts for each mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d638e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in range(outputmodes):\n",
    "    rmsepom = errorarrays[mode]\n",
    "\n",
    "    print(\"=========================================================\")\n",
    "    print('Error in '+yvar+' predictions using RFs with Output Mode = {}'.format(outputname[mode]))\n",
    "    print('RMSE % minimum: ', rmsepom.min())\n",
    "    print('RMSE % maximum: ', rmsepom.max())\n",
    "    print('RMSE % mean: ', rmsepom.mean())\n",
    "    print(\"=========================================================\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Contour levels for 'zoomed out'\n",
    "    clev = np.arange(0,30,2)  #contour levels\n",
    "    draw(rmsepom)\n",
    "    \n",
    "    #Contour levels for 5%\n",
    "    clev = np.arange(0,5,.25)  #contour levels\n",
    "    draw(rmsepom)\n",
    "    \n",
    "    drawerror(rmsepom)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
