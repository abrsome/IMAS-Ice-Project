{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b6a3795",
   "metadata": {},
   "source": [
    "# RF SIE Output Modes by Month\n",
    "\n",
    "This is the script for the main version of the random forest model. This script looks at building and evaluating models for SIE regression with different modes of prediction, it does not actually compute a 20th century regression (for that, look at _RF SIE 1903 Prediction_).\n",
    "\n",
    "---\n",
    "\n",
    "By __different modes of prediction__ I mean the following: We can build a random forest predicting sea ice for each intersection of time (i.e. month) and longitude (10 degree section), meaning that we have a separate model for each grid square on a graph representing month against longitude. However, this does not consider the relationship between the dependent variables (the relationship between sea ice in one month or longitude section and another), so we can create different output 'modes' to do this.\n",
    "\n",
    "The modes of prediction are:\n",
    "- Individual = consider each time/longitude section separately\n",
    "- Month = consider data from all longitudes in a month as one target\n",
    "- Longitudinal = consider data from all months in that longitude as one target\n",
    "- Year = consider the entire year's data as a target variable\n",
    "\n",
    "For example, in the 'Month' mode, we create 12 different models (12 different RFs), and each one sees all of the data for all the longitudes for one specific month, and it then goes on to predict data for all the longitudes for that one month, taking into account the relationship between SIE at different longitudes as it does so. This prediction is then unravelled back into the values for each longitude section for the purpose of analysing the error.\n",
    "\n",
    "The Individual mode uses 12 * 36 = 432 distinct models for the prediction, Month uses 12, Longitudinal uses 36, and Year uses one. This means that the ratio of predictors to dependent variables is different in each model (highest in Individual and lowest in Year), and different relationships between sections of SIE are considered in each mode (more relationships in Year and none in Individual), resulting in different accuracy of prediction across the modes.\n",
    "\n",
    "__Note:__ I believe there is room for improvement here, by investigating different groupings of SIE, for example using a model that only forecasts the Bellingshausen Sea, or one that considers the Sea in the summer and winter independently. There is a lot that can be done in searching for a combination of groupings that produce the best predictions for the whole SIE.\n",
    "\n",
    "---\n",
    "\n",
    "### Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f434f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from calendar import month_abbr "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f76d3d1",
   "metadata": {},
   "source": [
    "Grab in the list of month contractions and pop the empty string so it can be used in the graphs for axis tick labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77ea37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = list(month_abbr)\n",
    "months.pop(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f4cb3b",
   "metadata": {},
   "source": [
    "Set the number of estimators (= trees in each forest), as well as seeding a random state for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0b991",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_est = 200 #number of estimators\n",
    "rs = 0 #random state\n",
    "np.random.seed(rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b03ceb",
   "metadata": {},
   "source": [
    "Next we specify the years which will be used for:\n",
    "- the start of the prediction period (predstartyear)\n",
    "- the start of the training/testing data (startyear)\n",
    "- the end of the training/testing data (endyear)\n",
    "- the number of years we are predicting for (predyears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d4f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predstartyear = 1979 #start of predicted period\n",
    "startyear = 1979 #start of training\n",
    "endyear = 1995 #end of training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acbae02",
   "metadata": {},
   "source": [
    "Then we specify filepaths and open the data for our prediction and training sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebce3c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "yvar = 'SIE'\n",
    "folder = '~/Desktop/IMAS/ncfiles/'  #filepath\n",
    "pfile = 'Proxy_combined_data_v4.nc'  #proxy filename\n",
    "xfile = 'CombinedProxies.nc'  #proxy filename\n",
    "df = xr.open_dataset(folder+pfile).sel(year= slice(startyear, endyear))\n",
    "X = xr.open_dataset(folder+xfile).sel(year= slice(predstartyear, endyear))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecab70d8",
   "metadata": {},
   "source": [
    "Then we drop predictors containing NaN values in this range.\n",
    "\n",
    "__Note:__ We must do this as RFs cannot handle NaN values, there are many alternative options here such as:\n",
    "- using the mean to impute values\n",
    "- using a RF based on other proxies in that year (or only complete years) to impute\n",
    "- using a known distribution to impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2673e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_dataframe().dropna(axis=1).to_xarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d690a952",
   "metadata": {},
   "source": [
    "As mentioned in the preamble, there are four modes of prediction, so we set that number here and construct an array with their names in the fixed order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b5553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputmodes = 4 #number of output modes\n",
    "outputname = ['Individual','Month','Longitudinal','Year']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a9cd3",
   "metadata": {},
   "source": [
    "Then log the mean SIE for use in calculating error%.\n",
    "\n",
    "__Note:__ you could also calculate the mean SIE in each month, or at each longitude, for different ways of considering the error. I have used this as it was the simplest to implement in a short amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd352b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_sie = df['SIE'].mean('month').mean('lon').mean('year')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c32c26",
   "metadata": {},
   "source": [
    "Next generate a train test split.\n",
    "\n",
    "I am doing this here by randomly selecting arrays of years instead of using sklearn traintest split as not all the splits are done simultaneously and therefore can't all be done in one call of the function to maintain the same splits. So, I need to generate year lists here to ensure the years in train/test data are consistent  across X and y's. Note that the split is seeded by the numpy random seed above to be reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b96efb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(startyear, endyear+1)\n",
    "testyears = np.sort(np.random.choice(years, size = int(len(years)*0.33), replace = False))\n",
    "trainyears = [x for x in years if x not in testyears]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80845d75",
   "metadata": {},
   "source": [
    "Select the correct section of predictor data for train/test and then standard scale them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e156e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.sel(year = trainyears).to_dataframe().values\n",
    "X_test = X.sel(year = testyears).to_dataframe().values\n",
    "\n",
    "#Standardise values of proxies\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830d5a84",
   "metadata": {},
   "source": [
    "Group the SIE into bins of 10 degree longitude sections for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77a6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[yvar].groupby_bins('lon', np.arange(0,361,10)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64277730",
   "metadata": {},
   "source": [
    "Initialise an empty array to store each array of the Root Mean Squared Error as Percentage of Mean (rmsepom) for the each model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde6062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "errorarrays = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ef1843",
   "metadata": {},
   "source": [
    "Loop through each of the modes, producing the models for each section and logging their error in rmsepom before appending rmsepom to errorarrays to save it.\n",
    "\n",
    "For the multioutput modes (not Individual) the test prediction is generated as an array of values, so we need to iterate through the array produced by the model to deconstruct it into the results for each time/longitude intersection.\n",
    "\n",
    "Note that the xarray dimension for month starts at 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0fa5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in range(outputmodes):\n",
    "    #Array to store root mean square error as percentage of mean\n",
    "    #RMSEPOM = Root Mean Squared Error as Percentage Of Mean\n",
    "    rmsepom = np.zeros([12,36]) #Initialise an array of correlations\n",
    "    \n",
    "    if(mode == 0): #Individual = consider each month/lon pair separately\n",
    "        for m in range(12): #loop over the months\n",
    "            m += 1 #month index in xarray starts at 1\n",
    "            monthdata = y.sel(month=m)\n",
    "            for long in range(36): \n",
    "                longend = (long+1)*10 #end of range of longitude section\n",
    "                monthlondata = monthdata.sel(lon_bins=longend)\n",
    "                y_train = monthlondata.sel(year = trainyears).to_numpy()\n",
    "                y_test = monthlondata.sel(year = testyears).to_numpy()\n",
    "                \n",
    "                #Training model\n",
    "                regressor = RandomForestRegressor(n_estimators = n_est, random_state = rs)\n",
    "                regressor.fit(X_train, y_train)\n",
    "                y_pred = regressor.predict(X_test)\n",
    "                rmse = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "                \n",
    "                #Put error into heatmap\n",
    "                rmsepom[m-1,int((longend-10)/10)] = 100*rmse/mean_sie\n",
    "        errorarrays.append(rmsepom) #Add in error array for this mode\n",
    "        \n",
    "    elif(mode == 1): #Month = consider data from all longitudes in a month as one target\n",
    "        for m in range(12): #loop over the months\n",
    "            m += 1 #month index in xarray starts at 1\n",
    "            monthdata = y.sel(month=m)\n",
    "            y_train = monthdata.sel(year = trainyears).to_numpy()\n",
    "            y_test = monthdata.sel(year = testyears).to_numpy()\n",
    "            \n",
    "            #Training model\n",
    "            regressor = RandomForestRegressor(n_estimators = n_est, random_state = rs)\n",
    "            regressor.fit(X_train, y_train)\n",
    "            y_pred = regressor.predict(X_test)\n",
    "            \n",
    "            #Convert nested arrays from longitudes to year time series\n",
    "            y_test = y_test.transpose()\n",
    "            y_pred = y_pred.transpose() \n",
    "            \n",
    "            for long in range(36):\n",
    "                rmse = np.sqrt(metrics.mean_squared_error(y_test[long], y_pred[long]))\n",
    "                rmsepom[m-1,long] = 100*rmse/mean_sie\n",
    "                \n",
    "        errorarrays.append(rmsepom) #Add in error array for this mode\n",
    "        \n",
    "    elif(mode == 2): #Longitudinal = consider data from all months in that longitude as one target\n",
    "        for long in range(36):\n",
    "            longend = (long+1)*10\n",
    "            longdata = y.sel(lon_bins = longend)\n",
    "            y_train = longdata.sel(year = trainyears).to_numpy()\n",
    "            y_test = longdata.sel(year = testyears).to_numpy()\n",
    "            \n",
    "            #Training model\n",
    "            regressor = RandomForestRegressor(n_estimators = n_est, random_state = rs)\n",
    "            regressor.fit(X_train, y_train)\n",
    "            y_pred = regressor.predict(X_test)\n",
    "            \n",
    "            #Convert nested arrays from months to year time series\n",
    "            y_test = y_test.transpose()\n",
    "            y_pred = y_pred.transpose() \n",
    "            \n",
    "            for m in range(12):\n",
    "                rmse = np.sqrt(metrics.mean_squared_error(y_test[m], y_pred[m]))\n",
    "                rmsepom[m, long] = 100*rmse/mean_sie\n",
    "        \n",
    "        errorarrays.append(rmsepom) #Add in error array for this mode\n",
    "    \n",
    "    elif(mode == 3): #Year = consider the entire year's data as a target variable\n",
    "        y_train = y.sel(year = trainyears).to_numpy()\n",
    "        y_train = y_train.reshape(y_train.shape[0], y_train.shape[1] * y_train.shape[2]) # 432 entries per year\n",
    "        y_test = y.sel(year = testyears).to_numpy()\n",
    "        \n",
    "        #Training model\n",
    "        regressor = RandomForestRegressor(n_estimators = n_est, random_state = rs)\n",
    "        regressor.fit(X_train, y_train)\n",
    "        y_pred = regressor.predict(X_test)\n",
    "        \n",
    "        #Transform pred and test into standard format to get time series\n",
    "        y_pred = y_pred.reshape(y_pred.shape[0],12,36).transpose()\n",
    "        y_test = y_test.transpose()\n",
    "        \n",
    "        \n",
    "        for l in range(36):\n",
    "            for m in range(12):\n",
    "                rmse = np.sqrt(metrics.mean_squared_error(y_test[l,m], y_pred[l,m]))\n",
    "                rmsepom[m,l] = 100*rmse/mean_sie   \n",
    "                \n",
    "        errorarrays.append(rmsepom) #Add in error array for this mode                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921690a8",
   "metadata": {},
   "source": [
    "---\n",
    "### Analysing the model\n",
    "\n",
    "First, define a function to plot a heatmap of the error from the model stored in rmsepom. This shows the RMSEPOM at each month/longitude section for the model with a colour scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a60a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(rmsepom):\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    rmsepomxr = xr.DataArray(rmsepom)\n",
    "    rmsepomxr.plot.pcolormesh(levels = clev)\n",
    "    \n",
    "    ax.set_title('Error in '+yvar+' predictions using RFs')\n",
    "    ax.set_ylabel('Month')\n",
    "    #plt.yticks(ticks=np.arange(12))\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_xticks(ticks=np.arange(3,36,3), labels=['','60E','','120E','','180','','120W','','60W',''])\n",
    "    ax.set_yticks(ticks=np.arange(12), labels=months, rotation=0)\n",
    "    ax.annotate(\"Mode = {}\".format(outputname[mode]), xy = (0,0), xytext = (-6,-2.1))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e32fdce",
   "metadata": {},
   "source": [
    "Next, define a function to plot the error distribution. This produces a histogram of the error values into 2% bins. It is also annotated with green, orange, and red lines to show where the 50th, 75th, and 95th percentiles of error respecitvely fall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649001f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawerror(rmsepom):\n",
    "    ax = plt.subplot()\n",
    "    \n",
    "    ordered = rmsepom.copy()\n",
    "    ordered.ravel().sort()\n",
    "    \n",
    "    x1 = np.percentile(ordered.ravel(), 50)\n",
    "    plt.plot([x1, x1], [0, 100], color='g', linestyle='dashed', linewidth=2)\n",
    "    ax.annotate(\"50%: {}\".format(round(x1,1)), xy = (35,100), color = 'g')\n",
    "    \n",
    "    x1 = np.percentile(ordered.ravel(), 75)\n",
    "    ax.annotate(\"75%: {}\".format(round(x1,1)), xy = (35,92.5), color = 'tab:orange')\n",
    "    plt.plot([x1, x1], [0, 100], color='tab:orange', linestyle='dashed', linewidth=2)\n",
    "    \n",
    "    x1 = np.percentile(ordered.ravel(), 95)\n",
    "    plt.plot([x1, x1], [0, 100], color='r', linestyle='dashed', linewidth=2)\n",
    "    ax.annotate(\"95%: {}\".format(round(x1,1)), xy = (35,85), color='r')\n",
    "    \n",
    "    plt.hist(ordered.ravel(), bins = np.arange(0,41,2))\n",
    "    \n",
    "    ax.set_title('Error distribution for mode: {}'.format(outputname[mode]))\n",
    "    ax.set_ylabel('Number of Values')\n",
    "    ax.set_xlabel('Error%')\n",
    "    ax.set_yticks(ticks=np.arange(0,120,10))\n",
    "    ax.set_xticks(ticks=np.arange(0,41,2))\n",
    "    ax.annotate(\"Estimators = {}\".format(n_est), xy = (0,0), xytext = (-6,-20))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad080e10",
   "metadata": {},
   "source": [
    "Finally, loop through each of the modes, putting the RMSEPOM array for that mode into the rmsepom variable. Then, produce some generic metrics and draw the 3 error charts for each mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af87c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in range(outputmodes):\n",
    "    rmsepom = errorarrays[mode]\n",
    "\n",
    "    print(\"=========================================================\")\n",
    "    print('Error in '+yvar+' predictions using RFs with Output Mode = {}'.format(outputname[mode]))\n",
    "    print('RMSE % minimum: ', rmsepom.min())\n",
    "    print('RMSE % maximum: ', rmsepom.max())\n",
    "    print('RMSE % mean: ', rmsepom.mean())\n",
    "    print(\"=========================================================\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Contour levels for 'zoomed out'\n",
    "    clev = np.arange(0,30,2)  #contour levels\n",
    "    draw(rmsepom)\n",
    "    \n",
    "    #Contour levels for 5%\n",
    "    clev = np.arange(0,5,.25)  #contour levels\n",
    "    draw(rmsepom)\n",
    "    \n",
    "    drawerror(rmsepom)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
